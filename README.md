# Dockerizing the Geocitizen Project

## Overview

This documentation provides an overview of the `docker-start.sh` script and the steps taken to dockerize the Ch-058 repo. As a conclusion, it seems that the project is currently broken, with branches that are more or less broken than the others. But this tool, enables a way to test them out fast and consistently (getting those 404 with everything saying it's all OK, but consistently). For more info about the scripts, "just ask" like this:

```sh
./docker-start --help
```

## The dockerization

At first, there was an attempt to do a `docker-compose.yml` file from the Dockerfiles of each service. But, without a static network, it defaulted to a "kind-of" private network that couldn't let the DB and the Backend service connect with each other. Or something like that, as the thing is, the maintainer doesn't really remember why those two couldn't connect under the `docker compose` network. To this point, there was sometime and somewhere in which a change was made, stopping the connection from both containers, even on plain `docker`! (host network) Always showed this error:

```
Could not open JPA EntityManager for transaction; nested exception is org.hibernate.exception.JDBCConnectionException: Unable to acquire JDBC Connection
```

There are still many doubts on how this was solved, but that's enough history. Let's talk about the images. The project hosted on the Ch-058 repo is called Geocitizen. From the maintainer's guessing on reading some of the code, this project is about placing markers on the map that issue contingent hazards or problems, such as those generated by the war on Ukraine. It also serves as sort of a Social-Media alike features, allowing the citizens to validate the trustability of these issues. This system composes of a DB on PostgreSQL (v10), connected via Liquibase (v3+), a backend developed on Java (v8), built with Maven (v3) and served on Apache Tomcat (v9). But also, it has a frontend, built on Vue (v2) with Webpack (v3), and both packaged within Npm (v10, Node12) and Babel (v6).

As every technology used is identified, it is about right to consider dockerize this project. More over if you consider that each of these versions called on the last paragraph were launched since more than 6 years ago. So, as it was a good idea, the process started. As usual, the files started as specific as posible with the only objective to run. Which, as a legacy project, wasn't so certain. But, as the Dockerfiles were being developed, they started to get more and more generalized. To the point that it started to become really easy and fast to test out more ways to get the services running. As the most notable example, the images that are file dependant, have a build step in which the files are taken directly from the Ch-058 repo, which allows to switch branches, and switch repos, forks, etc. All in the aim of get the services to actually run.

## Explanation of the structure

Here are the changes made on a tree structure:
```
docker
├── backend-config
│   ├── config-fixes.sh
│   ├── context.xml
│   └── tomcat-users.xml
├── backend.Dockerfile
├── db.Dockerfile
├── frontend-config
│   ├── package-lock.json
│   └── package.json
├── frontend.Dockerfile
└── old_backend.Dockerfile
docker-start.sh
docker-stop.sh
```

As more details on the scripts may be seen with the actual interaction, this section will mostly talk about the docker folder. First up, the sub-folders, both serve the same purpose, to get files/scripts that complete the builds of the images. In the case of the backend, it is done using regex only, the frontend by the other side, just use copies of the package files, because the lockfile is what actually got it running. I tested to do otherwise, without the lockfile, and the list of errors was endless, so it was kept like this for sanity. The only exception to this rules, are the XML files on the backend configs folder. Those serve the only purpose of get the /manager/html route available on the tomcat server, to get access to manager tools. With those files, it give access to user admin and password admin.

With the sub-folder out of the way, let's talk about the docker files. First up, every old_* structured name is not being used, it is saved only for debugging purposes. Now, the DB first, this image is a default image of PostgreSQLv10, it just has previous configuration of defaults, so it can be configured on the docker-start script. In the other hand, the frontend uses a builder/runner pattern, to avoid having more dependencies than the bare minimum on the running stage of the image. Finally, the backend image is a manual install of maven, tomcat and everything else on Ubuntu 16.04, just to match all the original dependencies of the project. But the results has been the same as running all on lightweights containers, (slim/alpine) there is no difference at the moment.
